{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82b2d70-528e-4d70-82d8-e09e3c6a9ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.4.1`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971c7adb-21bc-45c6-9739-19d3542686c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4caaef5-6fb9-4333-8b72-ed1115989f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "23/08/20 17:13:34 WARN Utils: Your hostname, Air.local resolves to a loopback address: 127.0.0.1; using 192.168.88.21 instead (on interface en5)\n",
      "23/08/20 17:13:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/08/20 17:13:34 INFO SparkContext: Running Spark version 3.4.1\n",
      "23/08/20 17:13:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/20 17:13:34 INFO ResourceUtils: ==============================================================\n",
      "23/08/20 17:13:34 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "23/08/20 17:13:34 INFO ResourceUtils: ==============================================================\n",
      "23/08/20 17:13:34 INFO SparkContext: Submitted application: Functions\n",
      "23/08/20 17:13:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "23/08/20 17:13:34 INFO ResourceProfile: Limiting resource is cpu\n",
      "23/08/20 17:13:34 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "23/08/20 17:13:34 INFO SecurityManager: Changing view acls to: vadim\n",
      "23/08/20 17:13:34 INFO SecurityManager: Changing modify acls to: vadim\n",
      "23/08/20 17:13:34 INFO SecurityManager: Changing view acls groups to: \n",
      "23/08/20 17:13:34 INFO SecurityManager: Changing modify acls groups to: \n",
      "23/08/20 17:13:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vadim; groups with view permissions: EMPTY; users with modify permissions: vadim; groups with modify permissions: EMPTY\n",
      "23/08/20 17:13:34 INFO Utils: Successfully started service 'sparkDriver' on port 64316.\n",
      "23/08/20 17:13:34 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/08/20 17:13:34 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/08/20 17:13:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "23/08/20 17:13:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "23/08/20 17:13:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/08/20 17:13:34 INFO DiskBlockManager: Created local directory at /private/var/folders/kz/dn9t1wpd407b4v0vzjyyrbjm0000gn/T/blockmgr-0aa83970-8f0d-4ef9-9510-d01b644dcfad\n",
      "23/08/20 17:13:34 INFO MemoryStore: MemoryStore started with capacity 2004.6 MiB\n",
      "23/08/20 17:13:35 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "23/08/20 17:13:35 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "23/08/20 17:13:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "23/08/20 17:13:35 INFO Executor: Starting executor ID driver on host 192.168.88.21\n",
      "23/08/20 17:13:35 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "23/08/20 17:13:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64317.\n",
      "23/08/20 17:13:35 INFO NettyBlockTransferService: Server created on 192.168.88.21:64317\n",
      "23/08/20 17:13:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "23/08/20 17:13:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.88.21, 64317, None)\n",
      "23/08/20 17:13:35 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.88.21:64317 with 2004.6 MiB RAM, BlockManagerId(driver, 192.168.88.21, 64317, None)\n",
      "23/08/20 17:13:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.88.21, 64317, None)\n",
      "23/08/20 17:13:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.88.21, 64317, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@1c4c06f8\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "                .builder()\n",
    "                .master(\"local[*]\")\n",
    "                .appName(\"Functions\")\n",
    "                .getOrCreate()\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb82f43-9e6f-4bcb-80d7-40a361767774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:36 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "23/08/20 17:13:36 INFO SharedState: Warehouse path is 'file:/Users/vadim/Projects/OtusTeam/SparkDeveloper/lesson-07/Notebooks/spark-warehouse'.\n",
      "23/08/20 17:13:37 INFO CodeGenerator: Code generated in 183.058166 ms\n",
      "23/08/20 17:13:38 INFO CodeGenerator: Code generated in 7.691208 ms\n",
      "23/08/20 17:13:38 INFO CodeGenerator: Code generated in 10.3405 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|\n",
      "+------------+--------+-----+--------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 4 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = Seq(\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 1, 300, 1551903533),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"NC\", 2, 120, 1551903567),\n",
    "    (\"Jean-Georges\", \"Perrin\", \"CA\" ,4, 75, 1551903599),\n",
    "    (\"Holden\", \"Karau\", \"CA\" , 6, 37, 1551904299),\n",
    "    (\"Ginni\", \"Rometty\", \"NY\", 7, 91, 1551916792),\n",
    "    (\"Holden\", \"Karau\", \"CA\", 4, 153, 1552876129)\n",
    ").toDF(\"firstName\", \"lastName\", \"state\", \"quantity\", \"revenue\", \"timestamp\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4511b195-2d41-41db-9ea5-5dc623f47cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- quantity: integer (nullable = false)\n",
      " |-- revenue: integer (nullable = false)\n",
      " |-- timestamp: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531fae9-0baa-4ede-93d1-8b701ac68783",
   "metadata": {},
   "source": [
    "## Array Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5812952-39e8-40b9-83f1-ceb87f32df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:39 INFO CodeGenerator: Code generated in 11.174791 ms\n",
      "23/08/20 17:13:39 INFO CodeGenerator: Code generated in 13.683333 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2 = data\n",
    "                .withColumn(\"k2v\", array($\"firstName\", $\"lastName\", $\"state\"))\n",
    "                .withColumn(\"k2n\", array(lit(\"FirstName\"), lit(\"LastName\"), lit(\"State\")))\n",
    "\n",
    "datak2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1659d289-550c-4ba4-ab16-617ae6da25d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:39 INFO CodeGenerator: Code generated in 8.04425 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datak2.where(array_contains($\"k2v\", \"CA\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337eedf-cec3-4d0f-88c5-0327ee36f616",
   "metadata": {},
   "source": [
    "## Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ea9f77-080a-4d62-8fc4-e37c0206f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:39 INFO CodeGenerator: Code generated in 9.522583 ms\n",
      "23/08/20 17:13:39 INFO CodeGenerator: Code generated in 15.85875 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2m\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2m = data.withColumn(\"k2m\", map(lit(\"FirstName\"), $\"firstName\", lit(\"LastName\"), $\"lastName\", lit(\"State\"), $\"state\"))\n",
    "\n",
    "datak2m.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d653367c-af17-47d8-9302-3b20f694a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:40 INFO CodeGenerator: Code generated in 8.999666 ms\n",
      "23/08/20 17:13:40 INFO CodeGenerator: Code generated in 19.821375 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2v                       |k2n                         |k2m                                                         |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[Jean-Georges, Perrin, NC]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[Jean-Georges, Perrin, CA]|[FirstName, LastName, State]|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[Ginni, Rometty, NY]      |[FirstName, LastName, State]|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[Holden, Karau, CA]       |[FirstName, LastName, State]|{FirstName -> Holden, LastName -> Karau, State -> CA}       |\n",
      "+------------+--------+-----+--------+-------+----------+--------------------------+----------------------------+------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2ma\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 7 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2ma = datak2.withColumn(\"k2m\", map_from_arrays($\"k2n\", $\"k2v\"))\n",
    "\n",
    "datak2ma.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174009f8-f995-43c8-857d-4f7afbcea3e4",
   "metadata": {},
   "source": [
    "## Date and Timestamp Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc68f1e7-2fc4-4c8f-819a-148308e6406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+-------------------+-----------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |recordTimestamp    |current                |\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+-----------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|2019-03-06 23:18:53|2023-08-20 17:13:40.654|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|2019-03-06 23:19:27|2023-08-20 17:13:40.654|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|2019-03-06 23:19:59|2023-08-20 17:13:40.654|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|2019-03-06 23:31:39|2023-08-20 17:13:40.654|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|2019-03-07 02:59:52|2023-08-20 17:13:40.654|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|2019-03-18 05:28:49|2023-08-20 17:13:40.654|\n",
      "+------------+--------+-----+--------+-------+----------+-------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatat\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datat = data\n",
    "                .withColumn(\"recordTimestamp\", to_timestamp($\"timestamp\"))\n",
    "                .withColumn(\"current\", current_timestamp)\n",
    "\n",
    "datat.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923bf8a5-a4da-48d2-99ea-faf664a7a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:41 INFO CodeGenerator: Code generated in 4.135208 ms\n",
      "23/08/20 17:13:41 INFO CodeGenerator: Code generated in 4.452167 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------------------------------+\n",
      "|recordTimestamp    |current            |datediff(current, recordTimestamp)|\n",
      "+-------------------+-------------------+----------------------------------+\n",
      "|2019-03-06 23:18:53|2023-08-20 17:13:41|1628                              |\n",
      "|2019-03-06 23:19:27|2023-08-20 17:13:41|1628                              |\n",
      "|2019-03-06 23:19:59|2023-08-20 17:13:41|1628                              |\n",
      "|2019-03-06 23:31:39|2023-08-20 17:13:41|1628                              |\n",
      "|2019-03-07 02:59:52|2023-08-20 17:13:41|1627                              |\n",
      "|2019-03-18 05:28:49|2023-08-20 17:13:41|1616                              |\n",
      "+-------------------+-------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datat.select($\"recordTimestamp\", $\"current\", datediff($\"current\", $\"recordTimestamp\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dd5f2-9d23-45ba-97dd-cb869fe5331f",
   "metadata": {},
   "source": [
    "## JSON Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9e0c1c-83c3-4d85-b8d0-790fb4b3c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:41 INFO CodeGenerator: Code generated in 7.491334 ms\n",
      "23/08/20 17:13:41 INFO CodeGenerator: Code generated in 11.462542 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |k2m                                                         |k2j                                                          |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|{FirstName -> Jean-Georges, LastName -> Perrin, State -> NC}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"NC\"}|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|{FirstName -> Jean-Georges, LastName -> Perrin, State -> CA}|{\"FirstName\":\"Jean-Georges\",\"LastName\":\"Perrin\",\"State\":\"CA\"}|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|{FirstName -> Ginni, LastName -> Rometty, State -> NY}      |{\"FirstName\":\"Ginni\",\"LastName\":\"Rometty\",\"State\":\"NY\"}      |\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|{FirstName -> Holden, LastName -> Karau, State -> CA}       |{\"FirstName\":\"Holden\",\"LastName\":\"Karau\",\"State\":\"CA\"}       |\n",
      "+------------+--------+-----+--------+-------+----------+------------------------------------------------------------+-------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdatak2j\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datak2j = datak2m.withColumn(\"k2j\", to_json($\"k2m\"))\n",
    "\n",
    "datak2j.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c5e15-5439-4cc5-8e9c-d4ca908cca3c",
   "metadata": {},
   "source": [
    "## Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8d80a2d-6636-4841-be49-646816ecbd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Ginni       |Rometty |NY   |7       |91     |1551916792|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "|Holden      |Karau   |CA   |4       |153    |1552876129|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 6 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data2 = data\n",
    "                .withColumn(\"a1\", array(lit(1), lit(2), lit(3), lit(4), lit(5)))\n",
    "                .withColumn(\"a2\", lit((1 to 5).toArray))\n",
    "\n",
    "data2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "886eb9f8-e8e1-451e-9c0f-74a393acb4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:41 INFO CodeGenerator: Code generated in 4.508667 ms\n",
      "23/08/20 17:13:42 INFO CodeGenerator: Code generated in 16.747041 ms\n",
      "23/08/20 17:13:42 INFO CodeGenerator: Code generated in 12.167208 ms\n",
      "23/08/20 17:13:42 INFO SparkContext: Starting job: show at cell14.sc:1\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Got job 0 (show at cell14.sc:1) with 1 output partitions\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Final stage: ResultStage 0 (show at cell14.sc:1)\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at show at cell14.sc:1), which has no missing parents\n",
      "23/08/20 17:13:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 2004.6 MiB)\n",
      "23/08/20 17:13:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 2004.6 MiB)\n",
      "23/08/20 17:13:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.88.21:64317 (size: 5.2 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at cell14.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/20 17:13:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "23/08/20 17:13:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.88.21, executor driver, partition 0, PROCESS_LOCAL, 7703 bytes) \n",
      "23/08/20 17:13:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "23/08/20 17:13:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1706 bytes result sent to driver\n",
      "23/08/20 17:13:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 218 ms on 192.168.88.21 (executor driver) (1/1)\n",
      "23/08/20 17:13:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:42 INFO DAGScheduler: ResultStage 0 (show at cell14.sc:1) finished in 0,362 s\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/20 17:13:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Job 0 finished: show at cell14.sc:1, took 0,434964 s\n",
      "23/08/20 17:13:42 INFO SparkContext: Starting job: show at cell14.sc:1\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Got job 1 (show at cell14.sc:1) with 4 output partitions\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Final stage: ResultStage 1 (show at cell14.sc:1)\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[2] at show at cell14.sc:1), which has no missing parents\n",
      "23/08/20 17:13:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.9 KiB, free 2004.6 MiB)\n",
      "23/08/20 17:13:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 2004.6 MiB)\n",
      "23/08/20 17:13:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.88.21:64317 (size: 5.2 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at show at cell14.sc:1) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "23/08/20 17:13:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0\n",
      "23/08/20 17:13:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.88.21, executor driver, partition 1, PROCESS_LOCAL, 7703 bytes) \n",
      "23/08/20 17:13:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (192.168.88.21, executor driver, partition 2, PROCESS_LOCAL, 7703 bytes) \n",
      "23/08/20 17:13:42 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (192.168.88.21, executor driver, partition 3, PROCESS_LOCAL, 7695 bytes) \n",
      "23/08/20 17:13:42 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (192.168.88.21, executor driver, partition 4, PROCESS_LOCAL, 7695 bytes) \n",
      "23/08/20 17:13:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "23/08/20 17:13:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
      "23/08/20 17:13:42 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)\n",
      "23/08/20 17:13:42 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)\n",
      "23/08/20 17:13:42 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1650 bytes result sent to driver\n",
      "23/08/20 17:13:42 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1656 bytes result sent to driver\n",
      "23/08/20 17:13:42 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1652 bytes result sent to driver\n",
      "23/08/20 17:13:42 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver\n",
      "23/08/20 17:13:42 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 20 ms on 192.168.88.21 (executor driver) (1/4)\n",
      "23/08/20 17:13:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 24 ms on 192.168.88.21 (executor driver) (2/4)\n",
      "23/08/20 17:13:42 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 25 ms on 192.168.88.21 (executor driver) (3/4)\n",
      "23/08/20 17:13:42 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 28 ms on 192.168.88.21 (executor driver) (4/4)\n",
      "23/08/20 17:13:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:42 INFO DAGScheduler: ResultStage 1 (show at cell14.sc:1) finished in 0,042 s\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/20 17:13:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "23/08/20 17:13:42 INFO DAGScheduler: Job 1 finished: show at cell14.sc:1, took 0,049164 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|firstName   |lastName|state|quantity|revenue|timestamp |a1             |a2             |dummy|\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |1       |300    |1551903533|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |NC   |2       |120    |1551903567|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Jean-Georges|Perrin  |CA   |4       |75     |1551903599|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|1    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|2    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|3    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|4    |\n",
      "|Holden      |Karau   |CA   |6       |37     |1551904299|[1, 2, 3, 4, 5]|[1, 2, 3, 4, 5]|5    |\n",
      "+------------+--------+-----+--------+-------+----------+---------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.withColumn(\"dummy\", explode($\"a1\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9904a83-620a-4537-9dd4-8a0dac8092be",
   "metadata": {},
   "source": [
    "## Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351a5cea-7668-4b03-a961-86658da77882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\n",
       "\u001b[36mwindowSpec\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@19fd7759"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "val windowSpec  = Window.partitionBy(\"firstName\", \"lastName\").orderBy(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "334205e6-b9b8-4dd2-b1df-8e801acd5833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 5.350041 ms\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Registering RDD 5 (show at cell16.sc:3) as input to shuffle 0\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Got map stage job 2 (show at cell16.sc:3) with 6 output partitions\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (show at cell16.sc:3)\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[5] at show at cell16.sc:3), which has no missing parents\n",
      "23/08/20 17:13:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KiB, free 2004.6 MiB)\n",
      "23/08/20 17:13:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 2004.6 MiB)\n",
      "23/08/20 17:13:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.88.21:64317 (size: 4.7 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[5] at show at cell16.sc:3) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "23/08/20 17:13:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 6 tasks resource profile 0\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (192.168.88.21, executor driver, partition 0, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (192.168.88.21, executor driver, partition 1, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:43 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (192.168.88.21, executor driver, partition 2, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:43 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8) (192.168.88.21, executor driver, partition 3, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:43 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9) (192.168.88.21, executor driver, partition 4, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:43 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 10) (192.168.88.21, executor driver, partition 5, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)\n",
      "23/08/20 17:13:43 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)\n",
      "23/08/20 17:13:43 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)\n",
      "23/08/20 17:13:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)\n",
      "23/08/20 17:13:43 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)\n",
      "23/08/20 17:13:43 INFO Executor: Running task 5.0 in stage 2.0 (TID 10)\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 13.830417 ms\n",
      "23/08/20 17:13:43 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:43 INFO Executor: Finished task 5.0 in stage 2.0 (TID 10). 1875 bytes result sent to driver\n",
      "23/08/20 17:13:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:43 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 98 ms on 192.168.88.21 (executor driver) (1/6)\n",
      "23/08/20 17:13:43 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1875 bytes result sent to driver\n",
      "23/08/20 17:13:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 10) in 98 ms on 192.168.88.21 (executor driver) (2/6)\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 105 ms on 192.168.88.21 (executor driver) (3/6)\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 105 ms on 192.168.88.21 (executor driver) (4/6)\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 106 ms on 192.168.88.21 (executor driver) (5/6)\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 110 ms on 192.168.88.21 (executor driver) (6/6)\n",
      "23/08/20 17:13:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:43 INFO DAGScheduler: ShuffleMapStage 2 (show at cell16.sc:3) finished in 0,134 s\n",
      "23/08/20 17:13:43 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/08/20 17:13:43 INFO DAGScheduler: running: Set()\n",
      "23/08/20 17:13:43 INFO DAGScheduler: waiting: Set()\n",
      "23/08/20 17:13:43 INFO DAGScheduler: failed: Set()\n",
      "23/08/20 17:13:43 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 12.422375 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 11.724875 ms\n",
      "23/08/20 17:13:43 INFO SparkContext: Starting job: show at cell16.sc:3\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Got job 3 (show at cell16.sc:3) with 1 output partitions\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Final stage: ResultStage 4 (show at cell16.sc:3)\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at show at cell16.sc:3), which has no missing parents\n",
      "23/08/20 17:13:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.2 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.88.21:64317 (size: 14.2 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at show at cell16.sc:3) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/20 17:13:43 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (192.168.88.21, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "23/08/20 17:13:43 INFO Executor: Running task 0.0 in stage 4.0 (TID 11)\n",
      "23/08/20 17:13:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.88.21:64317 in memory (size: 5.2 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.88.21:64317 in memory (size: 5.2 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:43 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.88.21:64317 in memory (size: 4.7 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:43 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/08/20 17:13:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 10.035417 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 8.757083 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 5.06525 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 3.224708 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 3.654625 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 2.413417 ms\n",
      "23/08/20 17:13:43 INFO CodeGenerator: Code generated in 3.646333 ms\n",
      "23/08/20 17:13:43 INFO Executor: Finished task 0.0 in stage 4.0 (TID 11). 4699 bytes result sent to driver\n",
      "23/08/20 17:13:43 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 165 ms on 192.168.88.21 (executor driver) (1/1)\n",
      "23/08/20 17:13:43 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:43 INFO DAGScheduler: ResultStage 4 (show at cell16.sc:3) finished in 0,202 s\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/20 17:13:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "23/08/20 17:13:43 INFO DAGScheduler: Job 3 finished: show at cell16.sc:3, took 0,219627 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataw\u001b[39m: \u001b[32mDataFrame\u001b[39m = [firstName: string, lastName: string ... 5 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataw = data.withColumn(\"row_number\", row_number.over(windowSpec))\n",
    "\n",
    "dataw.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76bdfc0e-b90a-49ea-85bc-9859ffce6068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:44 INFO DAGScheduler: Registering RDD 13 (show at cell17.sc:1) as input to shuffle 1\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Got map stage job 4 (show at cell17.sc:1) with 6 output partitions\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (show at cell17.sc:1)\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[13] at show at cell17.sc:1), which has no missing parents\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.9 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.88.21:64317 (size: 4.7 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[13] at show at cell17.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Adding task set 5.0 with 6 tasks resource profile 0\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 12) (192.168.88.21, executor driver, partition 0, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 13) (192.168.88.21, executor driver, partition 1, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 14) (192.168.88.21, executor driver, partition 2, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 15) (192.168.88.21, executor driver, partition 3, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 16) (192.168.88.21, executor driver, partition 4, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 17) (192.168.88.21, executor driver, partition 5, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:44 INFO Executor: Running task 0.0 in stage 5.0 (TID 12)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 4.0 in stage 5.0 (TID 16)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 3.0 in stage 5.0 (TID 15)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 5.0 in stage 5.0 (TID 17)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 2.0 in stage 5.0 (TID 14)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 1.0 in stage 5.0 (TID 13)\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 0.0 in stage 5.0 (TID 12). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 4.0 in stage 5.0 (TID 16). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 5.0 in stage 5.0 (TID 17). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 16) in 35 ms on 192.168.88.21 (executor driver) (1/6)\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 2.0 in stage 5.0 (TID 14). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 3.0 in stage 5.0 (TID 15). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 1.0 in stage 5.0 (TID 13). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 12) in 44 ms on 192.168.88.21 (executor driver) (2/6)\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 15) in 45 ms on 192.168.88.21 (executor driver) (3/6)\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 13) in 46 ms on 192.168.88.21 (executor driver) (4/6)\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 17) in 43 ms on 192.168.88.21 (executor driver) (5/6)\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 14) in 47 ms on 192.168.88.21 (executor driver) (6/6)\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:44 INFO DAGScheduler: ShuffleMapStage 5 (show at cell17.sc:1) finished in 0,069 s\n",
      "23/08/20 17:13:44 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/08/20 17:13:44 INFO DAGScheduler: running: Set()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: waiting: Set()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: failed: Set()\n",
      "23/08/20 17:13:44 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 17.799 ms\n",
      "23/08/20 17:13:44 INFO SparkContext: Starting job: show at cell17.sc:1\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Got job 5 (show at cell17.sc:1) with 1 output partitions\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Final stage: ResultStage 7 (show at cell17.sc:1)\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[18] at show at cell17.sc:1), which has no missing parents\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.6 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.88.21:64317 (size: 14.4 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at show at cell17.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 18) (192.168.88.21, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "23/08/20 17:13:44 INFO Executor: Running task 0.0 in stage 7.0 (TID 18)\n",
      "23/08/20 17:13:44 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/08/20 17:13:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 0.0 in stage 7.0 (TID 18). 4658 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 18) in 26 ms on 192.168.88.21 (executor driver) (1/1)\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:44 INFO DAGScheduler: ResultStage 7 (show at cell17.sc:1) finished in 0,039 s\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Job 5 finished: show at cell17.sc:1, took 0,047328 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|\n",
      "+------------+--------+-----+--------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.where($\"row_number\" === 1).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea680ad-9eb7-443d-bc29-b54a343b2141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/20 17:13:44 INFO DAGScheduler: Registering RDD 21 (show at cell18.sc:1) as input to shuffle 2\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Got map stage job 6 (show at cell18.sc:1) with 6 output partitions\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (show at cell18.sc:1)\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[21] at show at cell18.sc:1), which has no missing parents\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.9 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 2004.5 MiB)\n",
      "23/08/20 17:13:44 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.88.21:64317 (size: 4.7 KiB, free: 2004.6 MiB)\n",
      "23/08/20 17:13:44 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[21] at show at cell18.sc:1) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Adding task set 8.0 with 6 tasks resource profile 0\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 19) (192.168.88.21, executor driver, partition 0, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 20) (192.168.88.21, executor driver, partition 1, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 21) (192.168.88.21, executor driver, partition 2, PROCESS_LOCAL, 7596 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 22) (192.168.88.21, executor driver, partition 3, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 23) (192.168.88.21, executor driver, partition 4, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 24) (192.168.88.21, executor driver, partition 5, PROCESS_LOCAL, 7588 bytes) \n",
      "23/08/20 17:13:44 INFO Executor: Running task 1.0 in stage 8.0 (TID 20)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 5.0 in stage 8.0 (TID 24)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 4.0 in stage 8.0 (TID 23)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 3.0 in stage 8.0 (TID 22)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 2.0 in stage 8.0 (TID 21)\n",
      "23/08/20 17:13:44 INFO Executor: Running task 0.0 in stage 8.0 (TID 19)\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 4.0 in stage 8.0 (TID 23). 1875 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 5.0 in stage 8.0 (TID 24). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 1.0 in stage 8.0 (TID 20). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 3.0 in stage 8.0 (TID 22). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 23) in 30 ms on 192.168.88.21 (executor driver) (1/6)\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 0.0 in stage 8.0 (TID 19). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 24) in 38 ms on 192.168.88.21 (executor driver) (2/6)\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 2.0 in stage 8.0 (TID 21). 1832 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 19) in 48 ms on 192.168.88.21 (executor driver) (3/6)\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 20) in 48 ms on 192.168.88.21 (executor driver) (4/6)\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 22) in 45 ms on 192.168.88.21 (executor driver) (5/6)\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 21) in 50 ms on 192.168.88.21 (executor driver) (6/6)\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:44 INFO DAGScheduler: ShuffleMapStage 8 (show at cell18.sc:1) finished in 0,074 s\n",
      "23/08/20 17:13:44 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/08/20 17:13:44 INFO DAGScheduler: running: Set()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: waiting: Set()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: failed: Set()\n",
      "23/08/20 17:13:44 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 14.588958 ms\n",
      "23/08/20 17:13:44 INFO SparkContext: Starting job: show at cell18.sc:1\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Got job 7 (show at cell18.sc:1) with 1 output partitions\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Final stage: ResultStage 10 (show at cell18.sc:1)\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Missing parents: List()\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[26] at show at cell18.sc:1), which has no missing parents\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 34.0 KiB, free 2004.4 MiB)\n",
      "23/08/20 17:13:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 2004.4 MiB)\n",
      "23/08/20 17:13:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.88.21:64317 (size: 15.1 KiB, free: 2004.5 MiB)\n",
      "23/08/20 17:13:44 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[26] at show at cell18.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 25) (192.168.88.21, executor driver, partition 0, NODE_LOCAL, 7363 bytes) \n",
      "23/08/20 17:13:44 INFO Executor: Running task 0.0 in stage 10.0 (TID 25)\n",
      "23/08/20 17:13:44 INFO ShuffleBlockFetcherIterator: Getting 6 (762.0 B) non-empty blocks including 6 (762.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/08/20 17:13:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 5.0975 ms\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 6.749792 ms\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 5.371917 ms\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 5.149333 ms\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 4.161959 ms\n",
      "23/08/20 17:13:44 INFO CodeGenerator: Code generated in 4.322 ms\n",
      "23/08/20 17:13:44 INFO Executor: Finished task 0.0 in stage 10.0 (TID 25). 4759 bytes result sent to driver\n",
      "23/08/20 17:13:44 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 25) in 79 ms on 192.168.88.21 (executor driver) (1/1)\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "23/08/20 17:13:44 INFO DAGScheduler: ResultStage 10 (show at cell18.sc:1) finished in 0,091 s\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/08/20 17:13:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished\n",
      "23/08/20 17:13:44 INFO DAGScheduler: Job 7 finished: show at cell18.sc:1, took 0,095585 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|   firstName|lastName|state|quantity|revenue| timestamp|row_number|revenue2|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "|       Ginni| Rometty|   NY|       7|     91|1551916792|         1|    null|\n",
      "|      Holden|   Karau|   CA|       6|     37|1551904299|         1|     153|\n",
      "|      Holden|   Karau|   CA|       4|    153|1552876129|         2|     153|\n",
      "|Jean-Georges|  Perrin|   CA|       4|     75|1551903599|         1|    null|\n",
      "|Jean-Georges|  Perrin|   NC|       1|    300|1551903533|         2|     300|\n",
      "|Jean-Georges|  Perrin|   NC|       2|    120|1551903567|         3|     300|\n",
      "+------------+--------+-----+--------+-------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataw.withColumn(\"revenue2\", nth_value($\"revenue\", 2).over(windowSpec)).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c7042-3b2c-4d32-a8cb-8aa8e6c5d252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
